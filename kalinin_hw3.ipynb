{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 08 декабря 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 08 декабря, -4 балла после 08:30 15 декабря, -6 баллов после 08:30 22 декабря, -8 баллов после 08:30 29 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(BaseEstimator):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini', purity_level = 0.95, rel_criterion_limit=0):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        self.purity_level = purity_level\n",
    "        self.rel_criterion_limit = rel_criterion_limit\n",
    "        # Для последнего задания\n",
    "        self.feature_importances = {}\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = dict()\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __div_ysamples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        p = np.array(np.unique(y, return_counts=True)[1])/y.shape[0]\n",
    "#         print(p, y, \"\\n\\n\")\n",
    "        if self.criterion == 'gini':\n",
    "            def F(p):\n",
    "                return 1 - (p*p).sum()\n",
    "        elif self.criterion == 'entropic':\n",
    "            def F(p):\n",
    "                return (p*p.log()).sum()\n",
    "        elif self.criterion == 'clf_loss':\n",
    "            def F(p):\n",
    "                return 1 - p.max()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported critetion\")\n",
    "        q_max = float('-inf')\n",
    "#         x_uni = np.unique(x, axis=0)\n",
    "        x_uni = x\n",
    "        complex_x_uni = x_uni + np.tile(np.arange(x_uni.shape[1]), [x_uni.shape[0], 1])*1.0j\n",
    "        def Q(val):\n",
    "            y_left, y_right = self.__div_ysamples(x, y, int(val.imag), val.real)\n",
    "            if y_left.shape[0] == 0 or y_right.shape[0] == 0:\n",
    "                return float('-inf')\n",
    "            p_left = np.array(np.unique(y_left, return_counts=True)[1])/y_left.shape[0]\n",
    "            p_right = np.array(np.unique(y_right, return_counts=True)[1])/y_right.shape[0]\n",
    "            q = - y_left.shape[0]/y.shape[0] * F(p_left) - y_right.shape[0]/y.shape[0] * F(p_right)\n",
    "            return q\n",
    "        Qs = np.vectorize(Q, otypes='f')(complex_x_uni)\n",
    "        max_feature = Qs.argmax() % Qs.shape[1]\n",
    "        max_threshold =  x_uni.ravel()[Qs.argmax()]\n",
    "#         print(max_feature, max_threshold)\n",
    "#         for ind, val in np.ndenumerate(np.unique(x, axis=1)):\n",
    "#             y_left, y_right = self.__div_ysamples(x, y, ind[1], val)\n",
    "#             if y_left.shape[0] == 0 or y_right.shape[0] == 0:\n",
    "#                 continue\n",
    "#             p_left = np.array(np.unique(y_left, return_counts=True)[1])/y_left.shape[0]\n",
    "#             p_right = np.array(np.unique(y_right, return_counts=True)[1])/y_right.shape[0]\n",
    "#             q = F(p)- y_left.shape[0]/y.shape[0] * F(p_left) - y_right.shape[0]/y.shape[0] * F(p_right)\n",
    "#             if q > q_max:\n",
    "#                 q_max = q\n",
    "#                 max_threshold = val\n",
    "#                 max_feature = ind[1]\n",
    "        return max_feature, max_threshold, F(p)-Qs.max()\n",
    "        \n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "#         print(x.shape, y.shape)\n",
    "        counts = np.unique(y, return_counts=True)\n",
    "        max_ratio = counts[1].max()/y.shape[0]\n",
    "        predict = counts[0][counts[1].argmax()]\n",
    "        if (x.shape[0] < self.min_samples_split) or depth >= self.max_depth or \\\n",
    "                max_ratio > self.purity_level:    \n",
    "            self.tree[node_id] = (self.__class__.LEAF_TYPE, predict, max_ratio)\n",
    "#             print(y,'\\n', counts, '\\n', self.tree[node_id], '\\n\\n')\n",
    "        else:\n",
    "            feature_id, threshold, q = self.__find_threshold(x, y)\n",
    "            if q < self.rel_criterion_limit:\n",
    "                counts = np.unique(y, return_counts=True)\n",
    "                self.tree[node_id] = (self.__class__.LEAF_TYPE, counts[0][counts[1].argmax()], counts[1].max()/y.shape[0])\n",
    "                return\n",
    "            self.tree[node_id] = (self.__class__.NON_LEAF_TYPE, feature_id, threshold)\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "            if feature_id in self.feature_importances.keys():\n",
    "                self.feature_importances[feature_id] += q\n",
    "            else:\n",
    "                self.feature_importances[feature_id] = q\n",
    "            self.__fit_node(x_left, y_left, 2*node_id+1, depth+1)\n",
    "            self.__fit_node(x_right, y_right, 2*node_id+2, depth+1)\n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        return self.feature_importances\n",
    "        # Ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6580468749999999"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(np.unique(y_train, return_counts=True)[1].argmax())\n",
    "# counts = np.unique(y_train, return_counts=True)\n",
    "# counts[0][counts[1].argmax()]\n",
    "criterion = 'gini'\n",
    "print(X_train.shape)\n",
    "p = np.array(np.unique(y_train, return_counts=True)[1])/y_train.shape[0]\n",
    "if criterion == 'gini':\n",
    "    def F(p):\n",
    "        return 1 - (p*p).sum()\n",
    "elif criterion == 'entropic':\n",
    "    def F(p):\n",
    "        return 1 - (p*p.log()).sum()\n",
    "elif criterion == 'clf_loss':\n",
    "    def F(p):\n",
    "        return 1 - p.max()\n",
    "else:\n",
    "    raise ValueError(\"Unsupported critetion\")\n",
    "\n",
    "F(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 2.97 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 46.9 ms, total: 1.47 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_clf.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Speed Dating Data.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Data columns (total 195 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   iid       8378 non-null   int64  \n",
      " 1   id        8377 non-null   float64\n",
      " 2   gender    8378 non-null   int64  \n",
      " 3   idg       8378 non-null   int64  \n",
      " 4   condtn    8378 non-null   int64  \n",
      " 5   wave      8378 non-null   int64  \n",
      " 6   round     8378 non-null   int64  \n",
      " 7   position  8378 non-null   int64  \n",
      " 8   positin1  6532 non-null   float64\n",
      " 9   order     8378 non-null   int64  \n",
      " 10  partner   8378 non-null   int64  \n",
      " 11  pid       8368 non-null   float64\n",
      " 12  match     8378 non-null   int64  \n",
      " 13  int_corr  8220 non-null   float64\n",
      " 14  samerace  8378 non-null   int64  \n",
      " 15  age_o     8274 non-null   float64\n",
      " 16  race_o    8305 non-null   float64\n",
      " 17  pf_o_att  8289 non-null   float64\n",
      " 18  pf_o_sin  8289 non-null   float64\n",
      " 19  pf_o_int  8289 non-null   float64\n",
      " 20  pf_o_fun  8280 non-null   float64\n",
      " 21  pf_o_amb  8271 non-null   float64\n",
      " 22  pf_o_sha  8249 non-null   float64\n",
      " 23  dec_o     8378 non-null   int64  \n",
      " 24  attr_o    8166 non-null   float64\n",
      " 25  sinc_o    8091 non-null   float64\n",
      " 26  intel_o   8072 non-null   float64\n",
      " 27  fun_o     8018 non-null   float64\n",
      " 28  amb_o     7656 non-null   float64\n",
      " 29  shar_o    7302 non-null   float64\n",
      " 30  like_o    8128 non-null   float64\n",
      " 31  prob_o    8060 non-null   float64\n",
      " 32  met_o     7993 non-null   float64\n",
      " 33  age       8283 non-null   float64\n",
      " 34  field     8315 non-null   object \n",
      " 35  field_cd  8296 non-null   float64\n",
      " 36  undergra  4914 non-null   object \n",
      " 37  mn_sat    3133 non-null   object \n",
      " 38  tuition   3583 non-null   object \n",
      " 39  race      8315 non-null   float64\n",
      " 40  imprace   8299 non-null   float64\n",
      " 41  imprelig  8299 non-null   float64\n",
      " 42  from      8299 non-null   object \n",
      " 43  zipcode   7314 non-null   object \n",
      " 44  income    4279 non-null   object \n",
      " 45  goal      8299 non-null   float64\n",
      " 46  date      8281 non-null   float64\n",
      " 47  go_out    8299 non-null   float64\n",
      " 48  career    8289 non-null   object \n",
      " 49  career_c  8240 non-null   float64\n",
      " 50  sports    8299 non-null   float64\n",
      " 51  tvsports  8299 non-null   float64\n",
      " 52  exercise  8299 non-null   float64\n",
      " 53  dining    8299 non-null   float64\n",
      " 54  museums   8299 non-null   float64\n",
      " 55  art       8299 non-null   float64\n",
      " 56  hiking    8299 non-null   float64\n",
      " 57  gaming    8299 non-null   float64\n",
      " 58  clubbing  8299 non-null   float64\n",
      " 59  reading   8299 non-null   float64\n",
      " 60  tv        8299 non-null   float64\n",
      " 61  theater   8299 non-null   float64\n",
      " 62  movies    8299 non-null   float64\n",
      " 63  concerts  8299 non-null   float64\n",
      " 64  music     8299 non-null   float64\n",
      " 65  shopping  8299 non-null   float64\n",
      " 66  yoga      8299 non-null   float64\n",
      " 67  exphappy  8277 non-null   float64\n",
      " 68  expnum    1800 non-null   float64\n",
      " 69  attr1_1   8299 non-null   float64\n",
      " 70  sinc1_1   8299 non-null   float64\n",
      " 71  intel1_1  8299 non-null   float64\n",
      " 72  fun1_1    8289 non-null   float64\n",
      " 73  amb1_1    8279 non-null   float64\n",
      " 74  shar1_1   8257 non-null   float64\n",
      " 75  attr4_1   6489 non-null   float64\n",
      " 76  sinc4_1   6489 non-null   float64\n",
      " 77  intel4_1  6489 non-null   float64\n",
      " 78  fun4_1    6489 non-null   float64\n",
      " 79  amb4_1    6489 non-null   float64\n",
      " 80  shar4_1   6467 non-null   float64\n",
      " 81  attr2_1   8299 non-null   float64\n",
      " 82  sinc2_1   8299 non-null   float64\n",
      " 83  intel2_1  8299 non-null   float64\n",
      " 84  fun2_1    8299 non-null   float64\n",
      " 85  amb2_1    8289 non-null   float64\n",
      " 86  shar2_1   8289 non-null   float64\n",
      " 87  attr3_1   8273 non-null   float64\n",
      " 88  sinc3_1   8273 non-null   float64\n",
      " 89  fun3_1    8273 non-null   float64\n",
      " 90  intel3_1  8273 non-null   float64\n",
      " 91  amb3_1    8273 non-null   float64\n",
      " 92  attr5_1   4906 non-null   float64\n",
      " 93  sinc5_1   4906 non-null   float64\n",
      " 94  intel5_1  4906 non-null   float64\n",
      " 95  fun5_1    4906 non-null   float64\n",
      " 96  amb5_1    4906 non-null   float64\n",
      " 97  dec       8378 non-null   int64  \n",
      " 98  attr      8176 non-null   float64\n",
      " 99  sinc      8101 non-null   float64\n",
      " 100 intel     8082 non-null   float64\n",
      " 101 fun       8028 non-null   float64\n",
      " 102 amb       7666 non-null   float64\n",
      " 103 shar      7311 non-null   float64\n",
      " 104 like      8138 non-null   float64\n",
      " 105 prob      8069 non-null   float64\n",
      " 106 met       8003 non-null   float64\n",
      " 107 match_es  7205 non-null   float64\n",
      " 108 attr1_s   4096 non-null   float64\n",
      " 109 sinc1_s   4096 non-null   float64\n",
      " 110 intel1_s  4096 non-null   float64\n",
      " 111 fun1_s    4096 non-null   float64\n",
      " 112 amb1_s    4096 non-null   float64\n",
      " 113 shar1_s   4096 non-null   float64\n",
      " 114 attr3_s   4000 non-null   float64\n",
      " 115 sinc3_s   4000 non-null   float64\n",
      " 116 intel3_s  4000 non-null   float64\n",
      " 117 fun3_s    4000 non-null   float64\n",
      " 118 amb3_s    4000 non-null   float64\n",
      " 119 satis_2   7463 non-null   float64\n",
      " 120 length    7463 non-null   float64\n",
      " 121 numdat_2  7433 non-null   float64\n",
      " 122 attr7_2   1984 non-null   float64\n",
      " 123 sinc7_2   1955 non-null   float64\n",
      " 124 intel7_2  1984 non-null   float64\n",
      " 125 fun7_2    1984 non-null   float64\n",
      " 126 amb7_2    1955 non-null   float64\n",
      " 127 shar7_2   1974 non-null   float64\n",
      " 128 attr1_2   7445 non-null   float64\n",
      " 129 sinc1_2   7463 non-null   float64\n",
      " 130 intel1_2  7463 non-null   float64\n",
      " 131 fun1_2    7463 non-null   float64\n",
      " 132 amb1_2    7463 non-null   float64\n",
      " 133 shar1_2   7463 non-null   float64\n",
      " 134 attr4_2   5775 non-null   float64\n",
      " 135 sinc4_2   5775 non-null   float64\n",
      " 136 intel4_2  5775 non-null   float64\n",
      " 137 fun4_2    5775 non-null   float64\n",
      " 138 amb4_2    5775 non-null   float64\n",
      " 139 shar4_2   5775 non-null   float64\n",
      " 140 attr2_2   5775 non-null   float64\n",
      " 141 sinc2_2   5775 non-null   float64\n",
      " 142 intel2_2  5775 non-null   float64\n",
      " 143 fun2_2    5775 non-null   float64\n",
      " 144 amb2_2    5775 non-null   float64\n",
      " 145 shar2_2   5775 non-null   float64\n",
      " 146 attr3_2   7463 non-null   float64\n",
      " 147 sinc3_2   7463 non-null   float64\n",
      " 148 intel3_2  7463 non-null   float64\n",
      " 149 fun3_2    7463 non-null   float64\n",
      " 150 amb3_2    7463 non-null   float64\n",
      " 151 attr5_2   4377 non-null   float64\n",
      " 152 sinc5_2   4377 non-null   float64\n",
      " 153 intel5_2  4377 non-null   float64\n",
      " 154 fun5_2    4377 non-null   float64\n",
      " 155 amb5_2    4377 non-null   float64\n",
      " 156 you_call  3974 non-null   float64\n",
      " 157 them_cal  3974 non-null   float64\n",
      " 158 date_3    3974 non-null   float64\n",
      " 159 numdat_3  1496 non-null   float64\n",
      " 160 num_in_3  668 non-null    float64\n",
      " 161 attr1_3   3974 non-null   float64\n",
      " 162 sinc1_3   3974 non-null   float64\n",
      " 163 intel1_3  3974 non-null   float64\n",
      " 164 fun1_3    3974 non-null   float64\n",
      " 165 amb1_3    3974 non-null   float64\n",
      " 166 shar1_3   3974 non-null   float64\n",
      " 167 attr7_3   2016 non-null   float64\n",
      " 168 sinc7_3   2016 non-null   float64\n",
      " 169 intel7_3  2016 non-null   float64\n",
      " 170 fun7_3    2016 non-null   float64\n",
      " 171 amb7_3    2016 non-null   float64\n",
      " 172 shar7_3   2016 non-null   float64\n",
      " 173 attr4_3   2959 non-null   float64\n",
      " 174 sinc4_3   2959 non-null   float64\n",
      " 175 intel4_3  2959 non-null   float64\n",
      " 176 fun4_3    2959 non-null   float64\n",
      " 177 amb4_3    2959 non-null   float64\n",
      " 178 shar4_3   2959 non-null   float64\n",
      " 179 attr2_3   2959 non-null   float64\n",
      " 180 sinc2_3   2959 non-null   float64\n",
      " 181 intel2_3  2959 non-null   float64\n",
      " 182 fun2_3    2959 non-null   float64\n",
      " 183 amb2_3    2959 non-null   float64\n",
      " 184 shar2_3   2016 non-null   float64\n",
      " 185 attr3_3   3974 non-null   float64\n",
      " 186 sinc3_3   3974 non-null   float64\n",
      " 187 intel3_3  3974 non-null   float64\n",
      " 188 fun3_3    3974 non-null   float64\n",
      " 189 amb3_3    3974 non-null   float64\n",
      " 190 attr5_3   2016 non-null   float64\n",
      " 191 sinc5_3   2016 non-null   float64\n",
      " 192 intel5_3  2016 non-null   float64\n",
      " 193 fun5_3    2016 non-null   float64\n",
      " 194 amb5_3    2016 non-null   float64\n",
      "dtypes: float64(174), int64(13), object(8)\n",
      "memory usage: 12.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid    id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0       1   1.0       0    1       1     1     10         7       NaN      4   \n",
       "1       1   1.0       0    1       1     1     10         7       NaN      3   \n",
       "2       1   1.0       0    1       1     1     10         7       NaN     10   \n",
       "3       1   1.0       0    1       1     1     10         7       NaN      5   \n",
       "4       1   1.0       0    1       1     1     10         7       NaN      7   \n",
       "...   ...   ...     ...  ...     ...   ...    ...       ...       ...    ...   \n",
       "8373  552  22.0       1   44       2    21     22        14      10.0      5   \n",
       "8374  552  22.0       1   44       2    21     22        13      10.0      4   \n",
       "8375  552  22.0       1   44       2    21     22        19      10.0     10   \n",
       "8376  552  22.0       1   44       2    21     22         3      10.0     16   \n",
       "8377  552   NaN       1   44       2    21     22         2      10.0     15   \n",
       "\n",
       "      ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "...   ...      ...      ...       ...     ...     ...      ...      ...   \n",
       "8373  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8374  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8375  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8376  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8377  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "\n",
       "      intel5_3  fun5_3  amb5_3  \n",
       "0          NaN     NaN     NaN  \n",
       "1          NaN     NaN     NaN  \n",
       "2          NaN     NaN     NaN  \n",
       "3          NaN     NaN     NaN  \n",
       "4          NaN     NaN     NaN  \n",
       "...        ...     ...     ...  \n",
       "8373       9.0     5.0     6.0  \n",
       "8374       9.0     5.0     6.0  \n",
       "8375       9.0     5.0     6.0  \n",
       "8376       9.0     5.0     6.0  \n",
       "8377       9.0     5.0     6.0  \n",
       "\n",
       "[8378 rows x 195 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info(max_cols=200)\n",
    "df\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iid.nunique()\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['idg'], axis=1)\n",
    "df = df.drop(['condtn'], axis=1)\n",
    "df = df.drop(['zipcode', 'from', 'career', 'tuition', 'undergra', 'mn_sat'], axis=1)\n",
    "df = df.drop(['expnum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>wave</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>totalsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>339</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>340</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>346</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>489</td>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>517</td>\n",
       "      <td>21</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>526</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  wave  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  totalsum\n",
       "312    28     2      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "828    58     3      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "838    59     3      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "918    67     3     20.0     15.0      20.0    20.0     5.0     10.0      90.0\n",
       "1530  105     4     30.0     15.0      20.0    20.0     0.0      5.0      90.0\n",
       "5004  339    13      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "5014  340    13      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "5114  346    14      NaN      NaN       NaN     NaN     NaN      NaN       0.0\n",
       "7221  489    19     20.0     10.0      20.0    20.0    20.0      0.0      90.0\n",
       "7586  517    21     15.0     20.0      20.0    20.0     5.0     10.0      90.0\n",
       "7784  526    21     10.0     10.0      30.0    20.0    10.0     15.0      95.0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = ((temp.wave < 6) | (temp.wave > 9)) & (temp.totalsum < 99)\n",
    "temp.loc[idx, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>wave</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>totalsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>132</td>\n",
       "      <td>6</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>16.67</td>\n",
       "      <td>100.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>12.77</td>\n",
       "      <td>19.15</td>\n",
       "      <td>17.02</td>\n",
       "      <td>17.02</td>\n",
       "      <td>14.89</td>\n",
       "      <td>19.15</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>134</td>\n",
       "      <td>6</td>\n",
       "      <td>6.67</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>17.78</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.56</td>\n",
       "      <td>100.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>135</td>\n",
       "      <td>6</td>\n",
       "      <td>18.18</td>\n",
       "      <td>22.73</td>\n",
       "      <td>18.18</td>\n",
       "      <td>13.64</td>\n",
       "      <td>13.64</td>\n",
       "      <td>13.64</td>\n",
       "      <td>100.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>136</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>229</td>\n",
       "      <td>9</td>\n",
       "      <td>21.43</td>\n",
       "      <td>16.67</td>\n",
       "      <td>21.43</td>\n",
       "      <td>16.67</td>\n",
       "      <td>11.90</td>\n",
       "      <td>11.90</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>230</td>\n",
       "      <td>9</td>\n",
       "      <td>23.81</td>\n",
       "      <td>23.81</td>\n",
       "      <td>23.81</td>\n",
       "      <td>23.81</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.38</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>231</td>\n",
       "      <td>9</td>\n",
       "      <td>18.60</td>\n",
       "      <td>20.93</td>\n",
       "      <td>23.26</td>\n",
       "      <td>23.26</td>\n",
       "      <td>2.33</td>\n",
       "      <td>11.63</td>\n",
       "      <td>100.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>232</td>\n",
       "      <td>9</td>\n",
       "      <td>17.78</td>\n",
       "      <td>17.78</td>\n",
       "      <td>17.78</td>\n",
       "      <td>17.78</td>\n",
       "      <td>13.33</td>\n",
       "      <td>15.56</td>\n",
       "      <td>100.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>233</td>\n",
       "      <td>9</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  wave  attr1_1  sinc1_1  intel1_1  fun1_1  amb1_1  shar1_1  totalsum\n",
       "1846  132     6    16.67    16.67     16.67   16.67   16.67    16.67    100.02\n",
       "1851  133     6    12.77    19.15     17.02   17.02   14.89    19.15    100.00\n",
       "1856  134     6     6.67    20.00     20.00   17.78   20.00    15.56    100.01\n",
       "1861  135     6    18.18    22.73     18.18   13.64   13.64    13.64    100.01\n",
       "1866  136     6      NaN      NaN       NaN     NaN     NaN      NaN      0.00\n",
       "...   ...   ...      ...      ...       ...     ...     ...      ...       ...\n",
       "3308  229     9    21.43    16.67     21.43   16.67   11.90    11.90    100.00\n",
       "3328  230     9    23.81    23.81     23.81   23.81    2.38     2.38    100.00\n",
       "3348  231     9    18.60    20.93     23.26   23.26    2.33    11.63    100.01\n",
       "3368  232     9    17.78    17.78     17.78   17.78   13.33    15.56    100.01\n",
       "3388  233     9    14.00    20.00     18.00   16.00   14.00    18.00    100.00\n",
       "\n",
       "[102 rows x 9 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = ((temp.wave >= 6) & (temp.wave <= 9))\n",
    "temp.loc[idx, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "(df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "(df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1']].sum(axis=1)\n",
    "df.loc[:, ['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1']] = \\\n",
    "(df.loc[:, ['attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2']].sum(axis=1)\n",
    "df.loc[:, ['attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2']] = \\\n",
    "(df.loc[:, ['attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "(df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "# df = df.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\n",
    "                                 \n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\n",
    "                                   \n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4184 entries, 0 to 4183\n",
      "Data columns (total 361 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   iid         4184 non-null   int64  \n",
      " 1   wave        4184 non-null   int64  \n",
      " 2   round       4184 non-null   int64  \n",
      " 3   position    4184 non-null   int64  \n",
      " 4   positin1    4184 non-null   float64\n",
      " 5   order       4184 non-null   int64  \n",
      " 6   partner     4184 non-null   int64  \n",
      " 7   pid         4184 non-null   float64\n",
      " 8   match       4184 non-null   int64  \n",
      " 9   int_corr    4184 non-null   float64\n",
      " 10  samerace    4184 non-null   int64  \n",
      " 11  age_o       4184 non-null   float64\n",
      " 12  race_o      4184 non-null   float64\n",
      " 13  pf_o_att    4184 non-null   float64\n",
      " 14  pf_o_sin    4184 non-null   float64\n",
      " 15  pf_o_int    4184 non-null   float64\n",
      " 16  pf_o_fun    4184 non-null   float64\n",
      " 17  pf_o_amb    4184 non-null   float64\n",
      " 18  pf_o_sha    4184 non-null   float64\n",
      " 19  dec_o       4184 non-null   int64  \n",
      " 20  attr_o      4184 non-null   float64\n",
      " 21  sinc_o      4184 non-null   float64\n",
      " 22  intel_o     4184 non-null   float64\n",
      " 23  fun_o       4184 non-null   float64\n",
      " 24  amb_o       4184 non-null   float64\n",
      " 25  shar_o      4184 non-null   float64\n",
      " 26  like_o      4184 non-null   float64\n",
      " 27  prob_o      4184 non-null   float64\n",
      " 28  met_o       4184 non-null   float64\n",
      " 29  age         4184 non-null   float64\n",
      " 30  field_cd    4184 non-null   float64\n",
      " 31  race        4184 non-null   float64\n",
      " 32  imprace     4184 non-null   float64\n",
      " 33  imprelig    4184 non-null   float64\n",
      " 34  goal        4184 non-null   float64\n",
      " 35  date        4184 non-null   float64\n",
      " 36  go_out      4184 non-null   float64\n",
      " 37  career_c    4184 non-null   float64\n",
      " 38  sports      4184 non-null   float64\n",
      " 39  tvsports    4184 non-null   float64\n",
      " 40  exercise    4184 non-null   float64\n",
      " 41  dining      4184 non-null   float64\n",
      " 42  museums     4184 non-null   float64\n",
      " 43  art         4184 non-null   float64\n",
      " 44  hiking      4184 non-null   float64\n",
      " 45  gaming      4184 non-null   float64\n",
      " 46  clubbing    4184 non-null   float64\n",
      " 47  reading     4184 non-null   float64\n",
      " 48  tv          4184 non-null   float64\n",
      " 49  theater     4184 non-null   float64\n",
      " 50  movies      4184 non-null   float64\n",
      " 51  concerts    4184 non-null   float64\n",
      " 52  music       4184 non-null   float64\n",
      " 53  shopping    4184 non-null   float64\n",
      " 54  yoga        4184 non-null   float64\n",
      " 55  exphappy    4184 non-null   float64\n",
      " 56  attr1_1     4184 non-null   float64\n",
      " 57  sinc1_1     4184 non-null   float64\n",
      " 58  intel1_1    4184 non-null   float64\n",
      " 59  fun1_1      4184 non-null   float64\n",
      " 60  amb1_1      4184 non-null   float64\n",
      " 61  shar1_1     4184 non-null   float64\n",
      " 62  attr4_1     4184 non-null   float64\n",
      " 63  sinc4_1     4184 non-null   float64\n",
      " 64  intel4_1    4184 non-null   float64\n",
      " 65  fun4_1      4184 non-null   float64\n",
      " 66  amb4_1      4184 non-null   float64\n",
      " 67  shar4_1     4184 non-null   float64\n",
      " 68  attr2_1     4184 non-null   float64\n",
      " 69  sinc2_1     4184 non-null   float64\n",
      " 70  intel2_1    4184 non-null   float64\n",
      " 71  fun2_1      4184 non-null   float64\n",
      " 72  amb2_1      4184 non-null   float64\n",
      " 73  shar2_1     4184 non-null   float64\n",
      " 74  attr3_1     4184 non-null   float64\n",
      " 75  sinc3_1     4184 non-null   float64\n",
      " 76  fun3_1      4184 non-null   float64\n",
      " 77  intel3_1    4184 non-null   float64\n",
      " 78  amb3_1      4184 non-null   float64\n",
      " 79  attr5_1     4184 non-null   float64\n",
      " 80  sinc5_1     4184 non-null   float64\n",
      " 81  intel5_1    4184 non-null   float64\n",
      " 82  fun5_1      4184 non-null   float64\n",
      " 83  amb5_1      4184 non-null   float64\n",
      " 84  dec         4184 non-null   int64  \n",
      " 85  attr        4184 non-null   float64\n",
      " 86  sinc        4184 non-null   float64\n",
      " 87  intel       4184 non-null   float64\n",
      " 88  fun         4184 non-null   float64\n",
      " 89  amb         4184 non-null   float64\n",
      " 90  shar        4184 non-null   float64\n",
      " 91  like        4184 non-null   float64\n",
      " 92  prob        4184 non-null   float64\n",
      " 93  met         4184 non-null   float64\n",
      " 94  match_es    4184 non-null   float64\n",
      " 95  attr1_s     4184 non-null   float64\n",
      " 96  sinc1_s     4184 non-null   float64\n",
      " 97  intel1_s    4184 non-null   float64\n",
      " 98  fun1_s      4184 non-null   float64\n",
      " 99  amb1_s      4184 non-null   float64\n",
      " 100 shar1_s     4184 non-null   float64\n",
      " 101 attr3_s     4184 non-null   float64\n",
      " 102 sinc3_s     4184 non-null   float64\n",
      " 103 intel3_s    4184 non-null   float64\n",
      " 104 fun3_s      4184 non-null   float64\n",
      " 105 amb3_s      4184 non-null   float64\n",
      " 106 satis_2     4184 non-null   float64\n",
      " 107 length      4184 non-null   float64\n",
      " 108 numdat_2    4184 non-null   float64\n",
      " 109 attr7_2     4184 non-null   float64\n",
      " 110 sinc7_2     4184 non-null   float64\n",
      " 111 intel7_2    4184 non-null   float64\n",
      " 112 fun7_2      4184 non-null   float64\n",
      " 113 amb7_2      4184 non-null   float64\n",
      " 114 shar7_2     4184 non-null   float64\n",
      " 115 attr1_2     4184 non-null   float64\n",
      " 116 sinc1_2     4184 non-null   float64\n",
      " 117 intel1_2    4184 non-null   float64\n",
      " 118 fun1_2      4184 non-null   float64\n",
      " 119 amb1_2      4184 non-null   float64\n",
      " 120 shar1_2     4184 non-null   float64\n",
      " 121 attr4_2     4184 non-null   float64\n",
      " 122 sinc4_2     4184 non-null   float64\n",
      " 123 intel4_2    4184 non-null   float64\n",
      " 124 fun4_2      4184 non-null   float64\n",
      " 125 amb4_2      4184 non-null   float64\n",
      " 126 shar4_2     4184 non-null   float64\n",
      " 127 attr2_2     4184 non-null   float64\n",
      " 128 sinc2_2     4184 non-null   float64\n",
      " 129 intel2_2    4184 non-null   float64\n",
      " 130 fun2_2      4184 non-null   float64\n",
      " 131 amb2_2      4184 non-null   float64\n",
      " 132 shar2_2     4184 non-null   float64\n",
      " 133 attr3_2     4184 non-null   float64\n",
      " 134 sinc3_2     4184 non-null   float64\n",
      " 135 intel3_2    4184 non-null   float64\n",
      " 136 fun3_2      4184 non-null   float64\n",
      " 137 amb3_2      4184 non-null   float64\n",
      " 138 attr5_2     4184 non-null   float64\n",
      " 139 sinc5_2     4184 non-null   float64\n",
      " 140 intel5_2    4184 non-null   float64\n",
      " 141 fun5_2      4184 non-null   float64\n",
      " 142 amb5_2      4184 non-null   float64\n",
      " 143 you_call    4184 non-null   float64\n",
      " 144 them_cal    4184 non-null   float64\n",
      " 145 date_3      4184 non-null   float64\n",
      " 146 numdat_3    4184 non-null   float64\n",
      " 147 num_in_3    4184 non-null   float64\n",
      " 148 attr1_3     4184 non-null   float64\n",
      " 149 sinc1_3     4184 non-null   float64\n",
      " 150 intel1_3    4184 non-null   float64\n",
      " 151 fun1_3      4184 non-null   float64\n",
      " 152 amb1_3      4184 non-null   float64\n",
      " 153 shar1_3     4184 non-null   float64\n",
      " 154 attr7_3     4184 non-null   float64\n",
      " 155 sinc7_3     4184 non-null   float64\n",
      " 156 intel7_3    4184 non-null   float64\n",
      " 157 fun7_3      4184 non-null   float64\n",
      " 158 amb7_3      4184 non-null   float64\n",
      " 159 shar7_3     4184 non-null   float64\n",
      " 160 attr4_3     4184 non-null   float64\n",
      " 161 sinc4_3     4184 non-null   float64\n",
      " 162 intel4_3    4184 non-null   float64\n",
      " 163 fun4_3      4184 non-null   float64\n",
      " 164 amb4_3      4184 non-null   float64\n",
      " 165 shar4_3     4184 non-null   float64\n",
      " 166 attr2_3     4184 non-null   float64\n",
      " 167 sinc2_3     4184 non-null   float64\n",
      " 168 intel2_3    4184 non-null   float64\n",
      " 169 fun2_3      4184 non-null   float64\n",
      " 170 amb2_3      4184 non-null   float64\n",
      " 171 shar2_3     4184 non-null   float64\n",
      " 172 attr3_3     4184 non-null   float64\n",
      " 173 sinc3_3     4184 non-null   float64\n",
      " 174 intel3_3    4184 non-null   float64\n",
      " 175 fun3_3      4184 non-null   float64\n",
      " 176 amb3_3      4184 non-null   float64\n",
      " 177 attr5_3     4184 non-null   float64\n",
      " 178 sinc5_3     4184 non-null   float64\n",
      " 179 intel5_3    4184 non-null   float64\n",
      " 180 fun5_3      4184 non-null   float64\n",
      " 181 amb5_3      4184 non-null   float64\n",
      " 182 iid_f       4184 non-null   int64  \n",
      " 183 wave_f      4184 non-null   int64  \n",
      " 184 round_f     4184 non-null   int64  \n",
      " 185 position_f  4184 non-null   int64  \n",
      " 186 positin1_f  4184 non-null   float64\n",
      " 187 order_f     4184 non-null   int64  \n",
      " 188 partner_f   4184 non-null   int64  \n",
      " 189 pid_f       4184 non-null   float64\n",
      " 190 age_o_f     4184 non-null   float64\n",
      " 191 race_o_f    4184 non-null   float64\n",
      " 192 pf_o_att_f  4184 non-null   float64\n",
      " 193 pf_o_sin_f  4184 non-null   float64\n",
      " 194 pf_o_int_f  4184 non-null   float64\n",
      " 195 pf_o_fun_f  4184 non-null   float64\n",
      " 196 pf_o_amb_f  4184 non-null   float64\n",
      " 197 pf_o_sha_f  4184 non-null   float64\n",
      " 198 dec_o_f     4184 non-null   int64  \n",
      " 199 attr_o_f    4184 non-null   float64\n",
      " 200 sinc_o_f    4184 non-null   float64\n",
      " 201 intel_o_f   4184 non-null   float64\n",
      " 202 fun_o_f     4184 non-null   float64\n",
      " 203 amb_o_f     4184 non-null   float64\n",
      " 204 shar_o_f    4184 non-null   float64\n",
      " 205 like_o_f    4184 non-null   float64\n",
      " 206 prob_o_f    4184 non-null   float64\n",
      " 207 met_o_f     4184 non-null   float64\n",
      " 208 age_f       4184 non-null   float64\n",
      " 209 field_cd_f  4184 non-null   float64\n",
      " 210 race_f      4184 non-null   float64\n",
      " 211 imprace_f   4184 non-null   float64\n",
      " 212 imprelig_f  4184 non-null   float64\n",
      " 213 goal_f      4184 non-null   float64\n",
      " 214 date_f      4184 non-null   float64\n",
      " 215 go_out_f    4184 non-null   float64\n",
      " 216 career_c_f  4184 non-null   float64\n",
      " 217 sports_f    4184 non-null   float64\n",
      " 218 tvsports_f  4184 non-null   float64\n",
      " 219 exercise_f  4184 non-null   float64\n",
      " 220 dining_f    4184 non-null   float64\n",
      " 221 museums_f   4184 non-null   float64\n",
      " 222 art_f       4184 non-null   float64\n",
      " 223 hiking_f    4184 non-null   float64\n",
      " 224 gaming_f    4184 non-null   float64\n",
      " 225 clubbing_f  4184 non-null   float64\n",
      " 226 reading_f   4184 non-null   float64\n",
      " 227 tv_f        4184 non-null   float64\n",
      " 228 theater_f   4184 non-null   float64\n",
      " 229 movies_f    4184 non-null   float64\n",
      " 230 concerts_f  4184 non-null   float64\n",
      " 231 music_f     4184 non-null   float64\n",
      " 232 shopping_f  4184 non-null   float64\n",
      " 233 yoga_f      4184 non-null   float64\n",
      " 234 exphappy_f  4184 non-null   float64\n",
      " 235 attr1_1_f   4184 non-null   float64\n",
      " 236 sinc1_1_f   4184 non-null   float64\n",
      " 237 intel1_1_f  4184 non-null   float64\n",
      " 238 fun1_1_f    4184 non-null   float64\n",
      " 239 amb1_1_f    4184 non-null   float64\n",
      " 240 shar1_1_f   4184 non-null   float64\n",
      " 241 attr4_1_f   4184 non-null   float64\n",
      " 242 sinc4_1_f   4184 non-null   float64\n",
      " 243 intel4_1_f  4184 non-null   float64\n",
      " 244 fun4_1_f    4184 non-null   float64\n",
      " 245 amb4_1_f    4184 non-null   float64\n",
      " 246 shar4_1_f   4184 non-null   float64\n",
      " 247 attr2_1_f   4184 non-null   float64\n",
      " 248 sinc2_1_f   4184 non-null   float64\n",
      " 249 intel2_1_f  4184 non-null   float64\n",
      " 250 fun2_1_f    4184 non-null   float64\n",
      " 251 amb2_1_f    4184 non-null   float64\n",
      " 252 shar2_1_f   4184 non-null   float64\n",
      " 253 attr3_1_f   4184 non-null   float64\n",
      " 254 sinc3_1_f   4184 non-null   float64\n",
      " 255 fun3_1_f    4184 non-null   float64\n",
      " 256 intel3_1_f  4184 non-null   float64\n",
      " 257 amb3_1_f    4184 non-null   float64\n",
      " 258 attr5_1_f   4184 non-null   float64\n",
      " 259 sinc5_1_f   4184 non-null   float64\n",
      " 260 intel5_1_f  4184 non-null   float64\n",
      " 261 fun5_1_f    4184 non-null   float64\n",
      " 262 amb5_1_f    4184 non-null   float64\n",
      " 263 dec_f       4184 non-null   int64  \n",
      " 264 attr_f      4184 non-null   float64\n",
      " 265 sinc_f      4184 non-null   float64\n",
      " 266 intel_f     4184 non-null   float64\n",
      " 267 fun_f       4184 non-null   float64\n",
      " 268 amb_f       4184 non-null   float64\n",
      " 269 shar_f      4184 non-null   float64\n",
      " 270 like_f      4184 non-null   float64\n",
      " 271 prob_f      4184 non-null   float64\n",
      " 272 met_f       4184 non-null   float64\n",
      " 273 match_es_f  4184 non-null   float64\n",
      " 274 attr1_s_f   4184 non-null   float64\n",
      " 275 sinc1_s_f   4184 non-null   float64\n",
      " 276 intel1_s_f  4184 non-null   float64\n",
      " 277 fun1_s_f    4184 non-null   float64\n",
      " 278 amb1_s_f    4184 non-null   float64\n",
      " 279 shar1_s_f   4184 non-null   float64\n",
      " 280 attr3_s_f   4184 non-null   float64\n",
      " 281 sinc3_s_f   4184 non-null   float64\n",
      " 282 intel3_s_f  4184 non-null   float64\n",
      " 283 fun3_s_f    4184 non-null   float64\n",
      " 284 amb3_s_f    4184 non-null   float64\n",
      " 285 satis_2_f   4184 non-null   float64\n",
      " 286 length_f    4184 non-null   float64\n",
      " 287 numdat_2_f  4184 non-null   float64\n",
      " 288 attr7_2_f   4184 non-null   float64\n",
      " 289 sinc7_2_f   4184 non-null   float64\n",
      " 290 intel7_2_f  4184 non-null   float64\n",
      " 291 fun7_2_f    4184 non-null   float64\n",
      " 292 amb7_2_f    4184 non-null   float64\n",
      " 293 shar7_2_f   4184 non-null   float64\n",
      " 294 attr1_2_f   4184 non-null   float64\n",
      " 295 sinc1_2_f   4184 non-null   float64\n",
      " 296 intel1_2_f  4184 non-null   float64\n",
      " 297 fun1_2_f    4184 non-null   float64\n",
      " 298 amb1_2_f    4184 non-null   float64\n",
      " 299 shar1_2_f   4184 non-null   float64\n",
      " 300 attr4_2_f   4184 non-null   float64\n",
      " 301 sinc4_2_f   4184 non-null   float64\n",
      " 302 intel4_2_f  4184 non-null   float64\n",
      " 303 fun4_2_f    4184 non-null   float64\n",
      " 304 amb4_2_f    4184 non-null   float64\n",
      " 305 shar4_2_f   4184 non-null   float64\n",
      " 306 attr2_2_f   4184 non-null   float64\n",
      " 307 sinc2_2_f   4184 non-null   float64\n",
      " 308 intel2_2_f  4184 non-null   float64\n",
      " 309 fun2_2_f    4184 non-null   float64\n",
      " 310 amb2_2_f    4184 non-null   float64\n",
      " 311 shar2_2_f   4184 non-null   float64\n",
      " 312 attr3_2_f   4184 non-null   float64\n",
      " 313 sinc3_2_f   4184 non-null   float64\n",
      " 314 intel3_2_f  4184 non-null   float64\n",
      " 315 fun3_2_f    4184 non-null   float64\n",
      " 316 amb3_2_f    4184 non-null   float64\n",
      " 317 attr5_2_f   4184 non-null   float64\n",
      " 318 sinc5_2_f   4184 non-null   float64\n",
      " 319 intel5_2_f  4184 non-null   float64\n",
      " 320 fun5_2_f    4184 non-null   float64\n",
      " 321 amb5_2_f    4184 non-null   float64\n",
      " 322 you_call_f  4184 non-null   float64\n",
      " 323 them_cal_f  4184 non-null   float64\n",
      " 324 date_3_f    4184 non-null   float64\n",
      " 325 numdat_3_f  4184 non-null   float64\n",
      " 326 num_in_3_f  4184 non-null   float64\n",
      " 327 attr1_3_f   4184 non-null   float64\n",
      " 328 sinc1_3_f   4184 non-null   float64\n",
      " 329 intel1_3_f  4184 non-null   float64\n",
      " 330 fun1_3_f    4184 non-null   float64\n",
      " 331 amb1_3_f    4184 non-null   float64\n",
      " 332 shar1_3_f   4184 non-null   float64\n",
      " 333 attr7_3_f   4184 non-null   float64\n",
      " 334 sinc7_3_f   4184 non-null   float64\n",
      " 335 intel7_3_f  4184 non-null   float64\n",
      " 336 fun7_3_f    4184 non-null   float64\n",
      " 337 amb7_3_f    4184 non-null   float64\n",
      " 338 shar7_3_f   4184 non-null   float64\n",
      " 339 attr4_3_f   4184 non-null   float64\n",
      " 340 sinc4_3_f   4184 non-null   float64\n",
      " 341 intel4_3_f  4184 non-null   float64\n",
      " 342 fun4_3_f    4184 non-null   float64\n",
      " 343 amb4_3_f    4184 non-null   float64\n",
      " 344 shar4_3_f   4184 non-null   float64\n",
      " 345 attr2_3_f   4184 non-null   float64\n",
      " 346 sinc2_3_f   4184 non-null   float64\n",
      " 347 intel2_3_f  4184 non-null   float64\n",
      " 348 fun2_3_f    4184 non-null   float64\n",
      " 349 amb2_3_f    4184 non-null   float64\n",
      " 350 shar2_3_f   4184 non-null   float64\n",
      " 351 attr3_3_f   4184 non-null   float64\n",
      " 352 sinc3_3_f   4184 non-null   float64\n",
      " 353 intel3_3_f  4184 non-null   float64\n",
      " 354 fun3_3_f    4184 non-null   float64\n",
      " 355 amb3_3_f    4184 non-null   float64\n",
      " 356 attr5_3_f   4184 non-null   float64\n",
      " 357 sinc5_3_f   4184 non-null   float64\n",
      " 358 intel5_3_f  4184 non-null   float64\n",
      " 359 fun5_3_f    4184 non-null   float64\n",
      " 360 amb5_3_f    4184 non-null   float64\n",
      "dtypes: float64(343), int64(18)\n",
      "memory usage: 11.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_final = df_male.merge(df_female,left_on=['pid'], right_on=['iid_f'])\n",
    "df_final = df_final.fillna(df_final.mean())\n",
    "df_final = df_final.drop(['income', 'income_f', 'field', 'field_f'], axis=1)\n",
    "df_final.info(max_cols=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df_final.match)\n",
    "X = np.array(df_final.drop(['match'], axis=1), dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-852009567343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmy_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-d87a108a441b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__fit_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__predict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-d87a108a441b>\u001b[0m in \u001b[0;36m__fit_node\u001b[0;34m(self, x, y, node_id, depth)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#             print(y,'\\n', counts, '\\n', self.tree[node_id], '\\n\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mfeature_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__find_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_criterion_limit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-d87a108a441b>\u001b[0m in \u001b[0;36m__find_threshold\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mQs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_x_uni\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mmax_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mQs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mmax_threshold\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mx_uni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/-/Anaconda/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2106\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/-/Anaconda/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                       for a in args]\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-d87a108a441b>\u001b[0m in \u001b[0;36mQ\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mp_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mp_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/-/Anaconda/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/-/Anaconda/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minv_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnonzero\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "my_clf.fit(X_train, y_train)\n",
    "accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8615751789976134"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_final = df_final.drop(['dec_o', 'dec', 'dec_o_f', 'dec_f'], axis=1)\n",
    "y = np.array(df_final.match)\n",
    "X = np.array(df_final.drop(['match'], axis=1), dtype='float64')\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "my_clf.fit(X_train, y_train)\n",
    "accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate, GroupKFold\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, purity_level = 1)\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "cross_val_score(my_clf, X, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "depths = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "sample_split = [2, 5, 10, 20]\n",
    "purity_levels = np.arange(0.85, 1.01, 0.01)\n",
    "\n",
    "for depth in depths:\n",
    "    for min_sample in samples_split:\n",
    "        for purity_level in purity_levels:\n",
    "            my_clf = MyDecisionTreeClassifier(min_samples_split=min_sample, purity_level = purity_level, depth=depth)\n",
    "            cur_score = cross_val_score(\n",
    "                my_clf, X, y, scoring=make_scorer('accuracy'))\n",
    "            print(cur_score.mean())\n",
    "            if cur_score.mean() > max_score:\n",
    "                max_score = cur_score.mean()\n",
    "                params = (depth, min_sample, purity_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5298741453903446 met\n",
      "1.42852625471541 shar_o\n",
      "1.2152064371330114 shar\n",
      "0.9607985927378481 met_f\n",
      "0.9533172491273615 you_call_f\n",
      "0.9012302036322297 amb5_1\n",
      "0.754687488079071 tv\n",
      "0.7362078105360954 dining\n",
      "0.717320592863762 you_call\n",
      "0.7104942952166635 theater\n",
      "0.6698141784118119 sinc1_2_f\n",
      "0.66853016357363 iid\n",
      "0.5245794822644474 pf_o_sha\n",
      "0.4691052901136422 positin1\n",
      "0.31999999999999984 field_cd\n",
      "0.2790011951969269 race_o\n",
      "0.2553336858027533 like\n",
      "0.19608159590951035 intel2_1\n"
     ]
    }
   ],
   "source": [
    "feat_dict = my_clf.get_feature_importance()\n",
    "indexes = sorted(feat_dict, key=feat_dict.get, reverse=True)\n",
    "scores = sorted(feat_dict.values(), reverse=True)\n",
    "# print(indexes)\n",
    "features = (np.array(list(df_final.columns))[indexes])\n",
    "for i in range(len(indexes)):\n",
    "    print(scores[i], features[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210023866348448"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(features, ('match'))\n",
    "small_df_final = df_final[list(features)+['match']]\n",
    "y = np.array(small_df_final.match)\n",
    "X = np.array(small_df_final.drop(['match'], axis=1), dtype='float64')\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, purity_level = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "my_clf.fit(X_train, y_train)\n",
    "accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
